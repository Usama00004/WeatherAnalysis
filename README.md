# ğŸŒ¦ï¸ Weather Data ETL Pipeline with Apache Airflow on AWS

This is a hands-on data engineering project where we build and automate an ETL (Extract, Transform, Load) pipeline to fetch current weather data from the **OpenWeatherMap API**, transform it, and load it into an **AWS S3 bucket** using **Apache Airflow**.

The entire project is carried out on the **AWS Cloud Platform** and introduces key Airflow concepts such as **DAGs**, **Operators**, and **Sensors**.



## ğŸ“Œ Project Objectives

- Extract real-time weather data from OpenWeatherMap API
- Transform the data into a structured format (e.g., JSON or CSV)
- Load the processed data into an AWS S3 bucket
- Automate the ETL process using Apache Airflow
- Schedule and monitor the pipeline using Airflow DAGs
- Deploy everything on AWS



## ğŸ› ï¸ Tech Stack

- **Apache Airflow** â€“ Workflow orchestration
- **Python** â€“ Data extraction and transformation
- **AWS S3** â€“ Cloud storage
- **OpenWeatherMap API** â€“ Data source
- **Docker** *(optional)* â€“ For local Airflow environment
- **AWS EC2 / MWAA** â€“ Deployment options



## ğŸ“‚ Project Structure

weather-etl-airflow/
â”‚
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ weather_etl_dag.py # Airflow DAG definition
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ extract.py # Extract weather data from API
â”‚ â”œâ”€â”€ transform.py # Process and clean the data
â”‚ â””â”€â”€ load.py # Upload data to AWS S3
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ Dockerfile # (Optional) Docker environment
â”œâ”€â”€ docker-compose.yaml # (Optional) Local Airflow setup
â””â”€â”€ README.md # Project documentation# WeatherAnalysis
